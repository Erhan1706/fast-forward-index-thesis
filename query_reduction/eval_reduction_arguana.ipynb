{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyterrier as pt\n",
    "from pyterrier.measures import nDCG, RR, MAP\n",
    "from fast_forward import OnDiskIndex, Mode\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "if not pt.started():\n",
    "    pt.init(tqdm=\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:13:05.540 [main] WARN org.terrier.structures.FSADocumentIndex - This index has fields, but FSADocumentIndex is used (which stores fields lengths on disk); If using field-based models such as BM25F, change to index.document.class in the index  properties file to FSAFieldDocumentIndex or FSADocumentIndexInMemFields to support efficient retrieval. If you don't use (e.g.) BM25F, this warning can be ignored\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:beir/arguana\")\n",
    "bm25 = pt.BatchRetrieve(\"../data/beir_arguana\", wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_topics = pd.read_csv(\"./reduced_queries/reduced_queries_arguana.csv\", usecols=[\"qid\", \"query\"])\n",
    "topics = dataset.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR(BM25)</td>\n",
       "      <td>0.240754</td>\n",
       "      <td>0.366152</td>\n",
       "      <td>0.251991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name     RR@10   nDCG@10   AP@1000\n",
       "0  BR(BM25)  0.240754  0.366152  0.251991"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [bm25],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 1000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR(BM25)</td>\n",
       "      <td>0.220898</td>\n",
       "      <td>0.333117</td>\n",
       "      <td>0.23314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name     RR@10   nDCG@10  AP@1000\n",
       "0  BR(BM25)  0.220898  0.333117  0.23314"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [bm25],\n",
    "    reduced_topics,\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 1000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dodo/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at Snowflake/snowflake-arctic-embed-m and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dodo/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fast_forward.encoder import TransformerEncoder\n",
    "import torch\n",
    "\n",
    "class SnowFlakeQueryEncoder(TransformerEncoder):\n",
    "  def __call__(self, texts):\n",
    "    query_prefix = 'Represent this sentence for searching relevant passages: '\n",
    "    queries_with_prefix = [\"{}{}\".format(query_prefix, i) for i in texts]\n",
    "    query_tokens = self.tokenizer(queries_with_prefix, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "\n",
    "    query_tokens.to(self.device)\n",
    "    self.model.eval()\n",
    "\n",
    "    #document_tokens =  self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        query_embeddings = self.model(**query_tokens)[0][:, 0]\n",
    "        #doument_embeddings = self.model(**document_tokens)[0][:, 0]\n",
    "\n",
    "    # normalize embeddings\n",
    "    query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "    #doument_embeddings = torch.nn.functional.normalize(doument_embeddings, p=2, dim=1)\n",
    "    return query_embeddings.detach().cpu().numpy()\n",
    "  \n",
    "q_encoder_artic = SnowFlakeQueryEncoder('Snowflake/snowflake-arctic-embed-m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8674/8674 [00:00<00:00, 1743238.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from fast_forward import OnDiskIndex, Mode\n",
    "from pathlib import Path\n",
    "\n",
    "ff_index_artic = OnDiskIndex.load(\n",
    "    Path(\"../datam/ffindex_arguana_snowflake_arctic_embed_m.h5\"), query_encoder=q_encoder_artic, mode=Mode.MAXP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_index_artic = ff_index_artic.to_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_forward.util.pyterrier import FFScore\n",
    "\n",
    "ff_score_artic = FFScore(ff_index_artic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_name):\n",
    "    min_val = df[column_name].min()\n",
    "    max_val = df[column_name].max()\n",
    "    df[column_name] = (df[column_name] - min_val) / (max_val-min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_artic = ~bm25 % 1000 >> ff_score_artic\n",
    "d_artic_red = pl_artic.transform(reduced_topics)\n",
    "\n",
    "normalize_column(d_artic_red, \"score\")\n",
    "normalize_column(d_artic_red, \"score_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_artic = pl_artic.transform(dataset.get_topics())\n",
    "normalize_column(d_artic, \"score\")\n",
    "normalize_column(d_artic, \"score_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_904/1697411020.py:5: DeprecationWarning: Coercion of a dataframe into a transformer is deprecated; use a pt.Transformer.from_df() instead\n",
      "  [d_artic >> ff_int],\n"
     ]
    }
   ],
   "source": [
    "from fast_forward.util.pyterrier import FFInterpolate\n",
    "ff_int = FFInterpolate(alpha=0.8)\n",
    "\n",
    "pt.Experiment(\n",
    "    [d_artic >> ff_int],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    "    names=[\"BM25 >> FF\"],\n",
    ").to_csv(f\"og_arguana_{ff_int.alpha}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduced Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_904/309830428.py:4: DeprecationWarning: Coercion of a dataframe into a transformer is deprecated; use a pt.Transformer.from_df() instead\n",
      "  [d_artic_red >> ff_int],\n"
     ]
    }
   ],
   "source": [
    "ff_int = FFInterpolate(alpha=0.0)\n",
    "\n",
    "pt.Experiment(\n",
    "    [d_artic_red >> ff_int],\n",
    "    reduced_topics,\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    "    names=[\"BM25 >> FF\"],\n",
    ").to_csv(f\"reduced_arguana_{ff_int.alpha}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
