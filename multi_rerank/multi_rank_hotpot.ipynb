{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.1 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyterrier as pt\n",
    "from fast_forward.util.pyterrier import FFInterpolate, FFScore\n",
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "from fast_forward.encoder import TransformerEncoder\n",
    "from fast_forward import OnDiskIndex, Mode\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(tqdm=\"notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"irds:beir/hotpotqa/test\")\n",
    "devset = pt.get_dataset(\"irds:beir/hotpotqa/dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(\"../data/mount/hotpotqa\", wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_name):\n",
    "    min_val = df[column_name].min()\n",
    "    max_val = df[column_name].max()\n",
    "    df[column_name] = (df[column_name] - min_val) / (max_val-min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse = bm25.transform(dataset.get_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dev = bm25.transform(devset.get_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse = pd.read_csv(\"hotpot_bm25.csv\")\n",
    "sparse_dev = pd.read_csv(\"hotpot_bm25_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cache(BR(BM25))</td>\n",
       "      <td>0.662417</td>\n",
       "      <td>0.512828</td>\n",
       "      <td>0.4344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name     RR@10   nDCG@10  AP@1000\n",
       "0  Cache(BR(BM25))  0.662417  0.512828   0.4344"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "pt.Experiment(\n",
    "    [~bm25],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 1000],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake-artic-embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnowFlakeQueryEncoder(TransformerEncoder):\n",
    "  def __call__(self, texts):\n",
    "    query_prefix = 'Represent this sentence for searching relevant passages: '\n",
    "    queries_with_prefix = [\"{}{}\".format(query_prefix, i) for i in texts]\n",
    "    query_tokens = self.tokenizer(queries_with_prefix, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "\n",
    "    query_tokens.to(self.device)\n",
    "    self.model.eval()\n",
    "\n",
    "    #document_tokens =  self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        query_embeddings = self.model(**query_tokens)[0][:, 0]\n",
    "        #doument_embeddings = self.model(**document_tokens)[0][:, 0]\n",
    "\n",
    "    # normalize embeddings\n",
    "    query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "    #doument_embeddings = torch.nn.functional.normalize(doument_embeddings, p=2, dim=1)\n",
    "    return query_embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dodo/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at Snowflake/snowflake-arctic-embed-m and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/dodo/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "q_encoder_artic = SnowFlakeQueryEncoder('Snowflake/snowflake-arctic-embed-m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5233329/5233329 [00:06<00:00, 833610.86it/s] \n"
     ]
    }
   ],
   "source": [
    "from fast_forward import OnDiskIndex, Mode\n",
    "from pathlib import Path\n",
    "\n",
    "ff_index_artic = OnDiskIndex.load(\n",
    "    Path(\"../datam/ffindex_hotpot_snowflake.h5\"), query_encoder=q_encoder_artic, mode=Mode.MAXP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ff_index_artic = ff_index_artic.to_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_artic = pd.read_csv(\"artic_hotpot_scores_norm.csv\")\n",
    "d_artic_dev = pd.read_csv(\"artic_hotpot_scores_dev_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artic</td>\n",
       "      <td>0.718133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   nDCG@10\n",
       "0  Artic  0.718133"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "      [pt.Transformer.from_df(d_artic) >> FFInterpolate(alpha=0.1)],\n",
    "      dataset.get_topics(),\n",
    "      dataset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic\"],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7414483030131003 0.3\n"
     ]
    }
   ],
   "source": [
    "alphas = [0, 0.025, 0.05, 0.1, 0.3, 0.5]\n",
    "max_val = 0\n",
    "optimal_alpha = -1 \n",
    "\n",
    "for alpha in alphas:\n",
    "  exp = pt.Experiment(\n",
    "      [pt.Transformer.from_df(d_artic_dev) >> FFInterpolate(alpha=alpha)],\n",
    "      devset.get_topics(),\n",
    "      devset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic + BGE\"],\n",
    "  )\n",
    "  if exp[\"nDCG@10\"].values[0] > max_val:\n",
    "    max_val = exp[\"nDCG@10\"].values[0]\n",
    "    optimal_alpha = alpha\n",
    "\n",
    "print(max_val, optimal_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal alpha for Artic only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artic</td>\n",
       "      <td>0.725542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   nDCG@10\n",
       "0  Artic  0.725542"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "      [pt.Transformer.from_df(d_artic) >> FFInterpolate(alpha=0.3)],\n",
    "      dataset.get_topics(),\n",
    "      dataset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic\"],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGEQueryEncoder(TransformerEncoder):\n",
    "  def __call__(self, texts):\n",
    "    encoded_input = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    # for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "    # encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "    encoded_input.to(self.device)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = self.model(**encoded_input)\n",
    "        # Perform pooling. In this case, cls pooling.\n",
    "        sentence_embeddings = model_output[0][:, 0]\n",
    "    # normalize embeddings\n",
    "    sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "    return sentence_embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dodo/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "q_encoder_bge = BGEQueryEncoder('BAAI/bge-base-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8674/8674 [00:00<00:00, 1563379.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from fast_forward import OnDiskIndex, Mode\n",
    "from pathlib import Path\n",
    "\n",
    "ff_index_bge = OnDiskIndex.load(\n",
    "    Path(\"../bge/ffindex_arguana_bge_base_en_v1_5.h5\"), query_encoder=q_encoder_bge, mode=Mode.MAXP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_index_bge = ff_index_bge.to_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_bge = pd.read_csv(\"bge_hotpot_scores_norm.csv\")\n",
    "d_bge_dev = pd.read_csv(\"bge_hotpot_scores_dev_norm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal alpha BGE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7169611923112339 0.5\n"
     ]
    }
   ],
   "source": [
    "alphas = [0, 0.025, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "max_val = 0\n",
    "optimal_alpha = -1 \n",
    "\n",
    "for alpha in alphas:\n",
    "  exp = pt.Experiment(\n",
    "      [pt.Transformer.from_df(d_bge_dev) >> FFInterpolate(alpha=alpha)],\n",
    "      devset.get_topics(),\n",
    "      devset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"BGE\"],\n",
    "  )\n",
    "  if exp[\"nDCG@10\"].values[0] > max_val:\n",
    "    max_val = exp[\"nDCG@10\"].values[0]\n",
    "    optimal_alpha = alpha\n",
    "\n",
    "print(max_val, optimal_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGE</td>\n",
       "      <td>0.695725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name   nDCG@10\n",
       "0  BGE  0.695725"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "      [pt.Transformer.from_df(d_bge) >> FFInterpolate(alpha=optimal_alpha)],\n",
    "      dataset.get_topics(),\n",
    "      dataset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"BGE\"],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artic + BGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_artic = pt.Transformer.from_df(d_artic)\n",
    "sc_bge = pt.Transformer.from_df(d_bge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_artic_dev = pt.Transformer.from_df(d_artic_dev)\n",
    "sc_bge_dev = pt.Transformer.from_df(d_bge_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid       object\n",
       "docid      int64\n",
       "docno     object\n",
       "rank       int64\n",
       "score    float64\n",
       "query     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_dev.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "qid            object\n",
       "docno           int64\n",
       "score_0       float64\n",
       "score         float64\n",
       "query          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_bge_dev.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_sparse_dev = pt.Transformer.from_df(sparse_dev)\n",
    "sc_artic_dev = pt.Transformer.from_df(d_artic_dev)\n",
    "sc_bge_dev = pt.Transformer.from_df(d_bge_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for bm25: 0.2, artic: 0.4 and bge: 0.4\n"
     ]
    }
   ],
   "source": [
    "combinations = [(0, 0.5, 0.5), (0.05, 0.425, 0.425), (0.2, 0.4, 0.4), \n",
    "                (0.1, 0.2, 0.7), (0.1, 0.7, 0.2), (0, 0.3, 0.7),\n",
    "                (0.1, 0.4, 0.5), (0.1, 0.5, 0.4), (0, 0.7, 0.3),\n",
    "                (0.05, 0.45, 0.5), (0.05, 0.5, 0.45), (0.025, 0.275, 0.7),\n",
    "                (0.025, 0.7, 0.275)]\n",
    "\n",
    "max_comb = [0, 0, 0]\n",
    "max_score = 0\n",
    "\n",
    "for combination in combinations:\n",
    "  exp = pt.Experiment(\n",
    "      [combination[0] * sc_sparse_dev + combination[1] * sc_artic_dev + combination[2] * sc_bge_dev],\n",
    "      devset.get_topics(),\n",
    "      devset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic + BGE\"],\n",
    "  )\n",
    "  if exp[\"nDCG@10\"].values[0] > max_score:\n",
    "    max_score = exp[\"nDCG@10\"].values[0]\n",
    "    max_comb = combination\n",
    "\n",
    "print(f\"Best alpha for bm25: {max_comb[0]}, artic: {max_comb[1]} and bge: {max_comb[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artic + BGE</td>\n",
       "      <td>0.752114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name   nDCG@10\n",
       "0  Artic + BGE  0.752114"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "  [0.25 * sc_sparse_dev + 0.5 * sc_artic_dev + 0.25 * sc_bge_dev],\n",
    "  devset.get_topics(),\n",
    "  devset.get_qrels(),\n",
    "  eval_metrics=[nDCG @ 10],\n",
    "  names=[\"Artic + BGE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_sparse = pt.Transformer.from_df(sparse)\n",
    "sc_artic = pt.Transformer.from_df(d_artic)\n",
    "sc_bge = pt.Transformer.from_df(d_bge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artic + BGE</td>\n",
       "      <td>0.734033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name   nDCG@10\n",
       "0  Artic + BGE  0.734033"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "   [0.25 * sc_sparse + 0.5 * sc_artic + 0.25 * sc_bge],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[nDCG @ 10],\n",
    "    names=[\"Artic + BGE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pathlib import Path\n",
    "from typing import Callable, Sequence, Union\n",
    "from fast_forward.encoder import Encoder\n",
    "import numpy as np\n",
    "\n",
    "## Need to override TransformerEncoder to include trust_remote_code=True in the \n",
    "## from_pretrained() call since GTE requires it\n",
    "class TransformerEncoder(Encoder):\n",
    "    \"\"\"Uses a pre-trained transformer model for encoding. Returns the pooler output.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, model: Union[str, Path], device: str = \"cpu\", **tokenizer_args\n",
    "    ) -> None:\n",
    "        \"\"\"Create a transformer encoder.\n",
    "\n",
    "        Args:\n",
    "            model (Union[str, Path]): Pre-trained transformer model (name or path).\n",
    "            device (str, optional): PyTorch device. Defaults to \"cpu\".\n",
    "            **tokenizer_args: Additional tokenizer arguments.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model, trust_remote_code=True)\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.device = device\n",
    "        self.tokenizer_args = tokenizer_args\n",
    "\n",
    "    def __call__(self, texts: Sequence[str]) -> np.ndarray:\n",
    "        inputs = self.tokenizer(texts, return_tensors=\"pt\", **self.tokenizer_args)\n",
    "        inputs.to(self.device)\n",
    "        embeddings = self.model(**inputs).pooler_output.detach().cpu().numpy()\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTEQueryEncoder(TransformerEncoder):\n",
    "  def __call__(self, texts):\n",
    "    batch_dict = self.tokenizer(texts, max_length=8192, padding=True, truncation=True, return_tensors='pt')\n",
    "    batch_dict.to(self.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      outputs = self.model(**batch_dict)\n",
    "      embeddings = outputs.last_hidden_state[:, 0]\n",
    "    return embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dodo/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "q_encoder_gte = GTEQueryEncoder('Alibaba-NLP/gte-base-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gte = pd.read_csv(\"gte_hotpot_scores_norm.csv\")\n",
    "d_gte_dev = pd.read_csv(\"gte_hotpot_scores_dev_norm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal alpha GTE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6990942194700993 0.5\n"
     ]
    }
   ],
   "source": [
    "alphas = [0, 0.025, 0.05, 0.1, 0.2, 0.3, 0.5]\n",
    "max_val = 0\n",
    "optimal_alpha = -1 \n",
    "\n",
    "for alpha in alphas:\n",
    "  exp = pt.Experiment(\n",
    "      [pt.Transformer.from_df(d_gte_dev) >> FFInterpolate(alpha=alpha)],\n",
    "      devset.get_topics(),\n",
    "      devset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"BGE\"],\n",
    "  )\n",
    "  if exp[\"nDCG@10\"].values[0] > max_val:\n",
    "    max_val = exp[\"nDCG@10\"].values[0]\n",
    "    optimal_alpha = alpha\n",
    "\n",
    "print(max_val, optimal_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGE</td>\n",
       "      <td>0.686382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name   nDCG@10\n",
       "0  BGE  0.686382"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "      [pt.Transformer.from_df(d_gte) >> FFInterpolate(alpha=optimal_alpha)],\n",
    "      dataset.get_topics(),\n",
    "      dataset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"BGE\"],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_artic = pt.Transformer.from_df(d_artic)\n",
    "sc_bge = pt.Transformer.from_df(d_bge)\n",
    "\n",
    "sc_artic_dev = pt.Transformer.from_df(d_artic_dev)\n",
    "sc_bge_dev = pt.Transformer.from_df(d_bge_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_bge = pt.Transformer.from_df(d_bge)\n",
    "sc_bge_dev = pt.Transformer.from_df(d_bge_dev)\n",
    "\n",
    "sc_gte = pt.Transformer.from_df(d_gte)\n",
    "sc_gte_dev = pt.Transformer.from_df(d_gte_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_sparse_dev = pt.Transformer.from_df(sparse_dev)\n",
    "sc_sparse = pt.Transformer.from_df(sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artic + GTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for bm25: 0.1, artic: 0.7 and gte: 0.2\n"
     ]
    }
   ],
   "source": [
    "combinations = [(0, 0.5, 0.5), (0.05, 0.425, 0.425), (0.2, 0.4, 0.4), \n",
    "                (0.1, 0.2, 0.7), (0.1, 0.7, 0.2), (0, 0.3, 0.7),\n",
    "                (0.1, 0.4, 0.5), (0.1, 0.5, 0.4), (0, 0.7, 0.3),\n",
    "                (0.05, 0.45, 0.5), (0.05, 0.5, 0.45), (0.025, 0.275, 0.7),\n",
    "                (0.025, 0.7, 0.275)]\n",
    "\n",
    "max_comb = [0, 0, 0]\n",
    "max_score = 0\n",
    "\n",
    "for combination in combinations:\n",
    "  exp = pt.Experiment(\n",
    "      [combination[0] * sc_sparse_dev + combination[1] * sc_artic_dev + combination[2] * sc_gte_dev],\n",
    "      devset.get_topics(),\n",
    "      devset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic + GTE\"],\n",
    "  )\n",
    "  if exp[\"nDCG@10\"].values[0] > max_score:\n",
    "    max_score = exp[\"nDCG@10\"].values[0]\n",
    "    max_comb = combination\n",
    "\n",
    "print(f\"Best alpha for bm25: {max_comb[0]}, artic: {max_comb[1]} and gte: {max_comb[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artic + GTE</td>\n",
       "      <td>0.74802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  nDCG@10\n",
       "0  Artic + GTE  0.74802"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "  [0.075 * sc_sparse_dev + 0.725 * sc_artic_dev + 0.2 * sc_gte_dev],\n",
    "  devset.get_topics(),\n",
    "  devset.get_qrels(),\n",
    "  eval_metrics=[nDCG @ 10],\n",
    "  names=[\"Artic + GTE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artic + GTE</td>\n",
       "      <td>0.731014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name   nDCG@10\n",
       "0  Artic + GTE  0.731014"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "   [0.75 * sc_sparse + 0.725 * sc_artic + 0.2 * sc_gte],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[nDCG @ 10],\n",
    "    names=[\"Artic + GTE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BGE + GTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for bm25: 0.2, bge: 0.4 and gte: 0.4\n"
     ]
    }
   ],
   "source": [
    "combinations = [(0, 0.5, 0.5), (0.05, 0.425, 0.425), (0.2, 0.4, 0.4), \n",
    "                (0.1, 0.2, 0.7), (0.1, 0.7, 0.2), (0, 0.3, 0.7),\n",
    "                (0.1, 0.4, 0.5), (0.1, 0.5, 0.4), (0, 0.7, 0.3),\n",
    "                (0.05, 0.45, 0.5), (0.05, 0.5, 0.45), (0.025, 0.275, 0.7),\n",
    "                (0.025, 0.7, 0.275)]\n",
    "\n",
    "max_comb = [0, 0, 0]\n",
    "max_score = 0\n",
    "\n",
    "for combination in combinations:\n",
    "  exp = pt.Experiment(\n",
    "      [combination[0] * sc_sparse_dev + combination[1] * sc_bge_dev + combination[2] * sc_gte_dev],\n",
    "      devset.get_topics(),\n",
    "      devset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic + GTE\"],\n",
    "  )\n",
    "  if exp[\"nDCG@10\"].values[0] > max_score:\n",
    "    max_score = exp[\"nDCG@10\"].values[0]\n",
    "    max_comb = combination\n",
    "\n",
    "print(f\"Best alpha for bm25: {max_comb[0]}, bge: {max_comb[1]} and gte: {max_comb[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGE + GTE</td>\n",
       "      <td>0.728803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name   nDCG@10\n",
       "0  BGE + GTE  0.728803"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "  [0.25 * sc_sparse_dev + 0.5 * sc_bge_dev + 0.25 * sc_gte_dev],\n",
    "  devset.get_topics(),\n",
    "  devset.get_qrels(),\n",
    "  eval_metrics=[nDCG @ 10],\n",
    "  names=[\"BGE + GTE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGE + GTE</td>\n",
       "      <td>0.712162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name   nDCG@10\n",
       "0  BGE + GTE  0.712162"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "   [0.25 * sc_sparse + 0.5 * sc_bge + 0.25 * sc_gte],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[nDCG @ 10],\n",
    "    names=[\"BGE + GTE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artic + BGE + GTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for bm25: 0.05, artic: 0.316 gte: 0.316 and bge: 0.316\n"
     ]
    }
   ],
   "source": [
    "\n",
    "combinations = [(0, 0.33, 0.33, 0.34), (0.05, 0.316, 0.316, 0.316), (0.025, 0.325, 0.325, 0.325), \n",
    "                (0.1, 0.1, 0.6, 0.1), (0.1, 0.6, 0.1, 0.1), (0.1, 0.1, 0.1, 0.6),\n",
    "                (0.2, 0.2, 0.4, 0.2), (0.2, 0.4, 0.2, 0.2), (0.2, 0.2, 0.2, 0.4),\n",
    "                (0.025, 0.175, 0.5, 0.3), (0.025, 0.5, 0.175, 0.3), (0.025, 0.3, 0.175, 0.5),\n",
    "                (0.025, 0.5, 0.3, 0.175), (0.0025, 0.3, 0.5, 0.1975), (0.0025, 0.5, 0.3, 0.1975), (0.0025, 0.1975, 0.5, 0.3),\n",
    "                (0.0025, 0.5, 0.1975, 0.3), (0.0025, 0.3, 0.1975, 0.5), (0.0025, 0.1975, 0.3, 0.5)]\n",
    "\n",
    "max_comb = [0, 0, 0, 0]\n",
    "max_score = 0\n",
    "\n",
    "for combination in combinations:\n",
    "  exp = pt.Experiment(\n",
    "      [combination[0] * sc_sparse_dev + combination[1] * sc_artic + combination[2] * sc_bge + combination[3] * sc_gte],\n",
    "      devset.get_topics(),\n",
    "      devset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic + BGE + GTE\"],\n",
    "  )\n",
    "  if exp[\"nDCG@10\"].values[0] > max_score:\n",
    "    max_score = exp[\"nDCG@10\"].values[0]\n",
    "    max_comb = combination\n",
    "\n",
    "print(f\"Best alpha for bm25: {max_comb[0]}, artic: {max_comb[1]} gte: {max_comb[3]} and bge: {max_comb[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artic + BGE + GTE</td>\n",
       "      <td>0.747185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   nDCG@10\n",
       "0  Artic + BGE + GTE  0.747185"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pt.Experiment(\n",
    "      [0.05 * sc_sparse_dev + 0.55 * sc_artic_dev + 0.3 * sc_bge_dev + 0.1 * sc_gte_dev],\n",
    "      devset.get_topics(),\n",
    "      devset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic + BGE + GTE\"],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Artic + BGE + GTE</td>\n",
       "      <td>0.730526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   nDCG@10\n",
       "0  Artic + BGE + GTE  0.730526"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pt.Experiment(\n",
    "      [0.05 * sc_sparse + 0.55  * sc_artic +  0.3  * sc_bge + 0.1 * sc_gte],\n",
    "      dataset.get_topics(),\n",
    "      dataset.get_qrels(),\n",
    "      eval_metrics=[nDCG @ 10],\n",
    "      names=[\"Artic + BGE + GTE\"],\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
